{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca12e366",
   "metadata": {},
   "source": [
    "#### Import necessary libraries and set display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5550e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datetime as dt\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from detecta import detect_peaks\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_rows',200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe64799",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain_df = pd.read_csv('../data/time_domain_windows.csv')\n",
    "freq_domain_df = pd.read_csv('../data/freq_domain_windows.csv')\n",
    "time_freq_domain_df = pd.read_csv('../data/time_freq_domain_windows.csv')\n",
    "dct_domain_df = pd.read_csv('../data/dct_windows.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc88799",
   "metadata": {},
   "source": [
    "### 5. Splitting and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49061772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, GroupShuffleSplit, GroupKFold, ParameterGrid, train_test_split, ShuffleSplit, BaseShuffleSplit, PredefinedSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_ml_pipe(X, y, groups, preprocessor, model, hyperparameters, score, \n",
    "                  randomized_iter, random_seed=1030):\n",
    "    \n",
    "    \"\"\"A function to collate performance of multiple model runs and optimize\n",
    "    hyperparameters through GridSearchCV.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : Unprocessed feature matrix\n",
    "    y : Target variable\n",
    "    preprocessor : A column transformer object that defines preprocessing on \n",
    "                    each feature; pass None if not required\n",
    "    model : Initialized model\n",
    "    model_params : Dict object of hyperparameters/regularization params\n",
    "                    to pass to GridSearchCV\n",
    "    score : Sklearn's scorer object (or metric string) that specifies\n",
    "            GridSearchCV scoring strategy\n",
    "    randomized_iter : Number of random iterations to run through to \n",
    "                        pick optimized params.\n",
    "      \n",
    "    Returns\n",
    "    -------\n",
    "    trial_results : list of dictionaries with salient information of each GSCV run\"\"\"\n",
    "    \n",
    "    trial_results = []\n",
    "    \n",
    "    for i in range(1,randomized_iter+1):\n",
    "        print('Running trial {}'.format(i))\n",
    "        random_state = random_seed*i\n",
    "        \n",
    "        iter_info = {'trail_iter':i,\n",
    "                     'random_state':random_state}\n",
    "        \n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=6, random_state=random_state)\n",
    "        other_index, test_index = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "        X_other, y_other, groups_other = X.iloc[other_index], y.iloc[other_index], groups.iloc[other_index]\n",
    "        X_test, y_test, groups_test = X.iloc[test_index], y.iloc[test_index], groups.iloc[test_index]\n",
    "\n",
    "        gkf = GroupKFold(n_splits=7)\n",
    "\n",
    "        pipe = make_pipeline(std_scaler, model)\n",
    "        grid = GridSearchCV(pipe, param_grid=hyperparameters, scoring=score,\n",
    "                            cv=gkf, return_train_score=True, verbose=True, n_jobs=-1)\n",
    "        grid.fit(X_other, y_other, groups=groups_other)\n",
    "        \n",
    "        iter_info['grid'] = grid\n",
    "        \n",
    "        if grid.scorer_.__dict__['_sign']<0:\n",
    "            best_score = abs(grid.score(X_test,y_test))\n",
    "            maximized = False\n",
    "        else:\n",
    "            best_score = grid.score(X_test,y_test)\n",
    "            maximized = True\n",
    "        \n",
    "        iter_info['best_test_score'] = {'score':best_score, 'maximized':maximized}\n",
    "        iter_info['best_params'] = grid.best_params_\n",
    "        iter_info['y_test_pred'] = grid.predict(X_test)\n",
    "        iter_info['cv_results'] = grid.cv_results_\n",
    "        \n",
    "        trial_results.append(iter_info)\n",
    "        print('Completed trial {}'.format(i))\n",
    "        \n",
    "    return trial_results\n",
    "\n",
    "\n",
    "def gather_trial_results(df, exclftrs, target, groupftr, preprocessor, model, \n",
    "                         hyperparameters, score, trials, trial_type):\n",
    "    X = df.drop(columns=exclftrs)\n",
    "    y = df[target]\n",
    "    groups = df[groupftr]\n",
    "    trial_results = group_ml_pipe(X, y, groups, preprocessor, model, hyperparameters, score, \n",
    "                                  randomized_iter=trials)\n",
    "    \n",
    "    for result in trial_results:\n",
    "        result['trial_type']=trial_type\n",
    "    return trial_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce41b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "model = SVC()\n",
    "hyperparameters = {'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "                  'svc__gamma': [0.01, 0.05, 0.1, 0.5, 1]}\n",
    "score = make_scorer(f1_score, average='macro')\n",
    "\n",
    "svc_timefreq_results = gather_trial_results(df=time_freq_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                            target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                            hyperparameters=hyperparameters, score=score, \n",
    "                                            trials=5, trial_type='time-freq')\n",
    "\n",
    "joblib.dump(svc_timefreq_results, '../results/svc_timefreq_results.pkl')\n",
    "\n",
    "\n",
    "svc_dct_results = gather_trial_results(df=dct_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                       target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                       hyperparameters=hyperparameters, score=score, \n",
    "                                       trials=5, trial_type='dct')\n",
    "\n",
    "joblib.dump(svc_dct_results, '../results/svc_dct_results.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a56cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "model = RandomForestClassifier()\n",
    "hyperparameters = {\n",
    "    'randomforestclassifier__max_features': [0.25, 0.5, 0.75, 1.0],\n",
    "    'randomforestclassifier__max_depth': [2, 4, 6, 8, 10, 12, 14]\n",
    "}\n",
    "\n",
    "score = make_scorer(f1_score, average='macro')\n",
    "\n",
    "\n",
    "rfc_timefreq_results = gather_trial_results(df=time_freq_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                            target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                            hyperparameters=hyperparameters, score=score,\n",
    "                                            trials=5, trial_type='time-freq')\n",
    "joblib.dump(rfc_timefreq_results, '../results/rfc_timefreq_results.pkl')\n",
    "\n",
    "\n",
    "rfc_dct_results = gather_trial_results(df=dct_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                       target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                       hyperparameters=hyperparameters, score=score,\n",
    "                                       trials=5, trial_type='dct')\n",
    "joblib.dump(rfc_dct_results, '../results/rfc_dct_results.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd97654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "alpha_arr = np.logspace(-5,5,11,base=10)\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "model = LogisticRegression()\n",
    "hyperparameters = {\n",
    "    'logisticregression__C': 1/alpha_arr,\n",
    "    'logisticregression__penalty':['l2'],\n",
    "    'logisticregression__max_iter':[10000],\n",
    "    'logisticregression__multi_class':['ovr'],\n",
    "    'logisticregression__solver':['liblinear']\n",
    "}\n",
    "\n",
    "score = make_scorer(f1_score, average='macro')\n",
    "\n",
    "\n",
    "lr_timefreq_results = gather_trial_results(df=time_freq_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                            target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                            hyperparameters=hyperparameters, score=score,\n",
    "                                            trials=5, trial_type='time-freq')\n",
    "joblib.dump(lr_timefreq_results, '../results/lr_timefreq_results.pkl')\n",
    "\n",
    "\n",
    "lr_dct_results = gather_trial_results(df=dct_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                       target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                       hyperparameters=hyperparameters, score=score,\n",
    "                                       trials=5, trial_type='dct')\n",
    "joblib.dump(lr_dct_results, '../results/lr_dct_results.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59411ef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import xgboost\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "model = xgboost.XGBClassifier(use_label_encoder=True, objective='multi:softprob', verbosity = 0, silent = True)\n",
    "\n",
    "hyperparameters = {\n",
    "    'xgbclassifier__learning_rate': [0.01,0.025,0.05,0.1,0.25,0.5,1],\n",
    "    'xgbclassifier__max_depth': [2, 4, 6, 8, 10, 12, 14]\n",
    "}\n",
    "\n",
    "score = make_scorer(f1_score, average='macro')\n",
    "\n",
    "xgb_timefreq_results = gather_trial_results(df=time_freq_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                            target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                            hyperparameters=hyperparameters, score=score,\n",
    "                                            trials=5, trial_type='time-freq')\n",
    "\n",
    "joblib.dump(xgb_timefreq_results, '../results/xgb_timefreq_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import xgboost\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "model = xgboost.XGBClassifier(use_label_encoder=True, objective='multi:softprob', verbosity = 0, silent = True)\n",
    "\n",
    "hyperparameters = {\n",
    "    'xgbclassifier__learning_rate': [0.01,0.025,0.05,0.1,0.25,0.5,1],\n",
    "    'xgbclassifier__max_depth': [2, 4, 6, 8, 10, 12, 14]\n",
    "}\n",
    "\n",
    "score = make_scorer(f1_score, average='macro')\n",
    "\n",
    "xgb_dct_results = gather_trial_results(df=dct_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                            target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                            hyperparameters=hyperparameters, score=score,\n",
    "                                            trials=5, trial_type='time-freq')\n",
    "\n",
    "joblib.dump(xgb_dct_results, '../results/xgb_dct_results.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsemproj",
   "language": "python",
   "name": "mlsemproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
