{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "089d4771",
   "metadata": {},
   "source": [
    "<h1><center>Splitting, Preprocessing, Cross Validation and Model Development</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1ff44",
   "metadata": {},
   "source": [
    "This notebook contains code for the following:\n",
    "1. Read processed data after windowing and feature engineering.\n",
    "2. Train-validation-test splitting (bearing the group structure) and feature scaling.\n",
    "3. Setting up Cross Validation pipeline using GridSearchCV.\n",
    "4. Each model-feature combination is run through 5 random states to estimate mean F1 macro.\n",
    "5. Save best estimator of model (random state x feature combination) along with predictions, best parameters, cross-validation results and other metadata using joblib library for model evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12e366",
   "metadata": {},
   "source": [
    "#### Import necessary libraries and set display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5550e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, GridSearchCV, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import xgboost\n",
    "\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_rows',200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bba2db",
   "metadata": {},
   "source": [
    "### 1. Read relevant data (as saved after feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe64799",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain_df = pd.read_csv('../data/time_domain_windows.csv')\n",
    "freq_domain_df = pd.read_csv('../data/freq_domain_windows.csv')\n",
    "time_freq_domain_df = pd.read_csv('../data/time_freq_domain_windows.csv')\n",
    "dct_domain_df = pd.read_csv('../data/dct_windows.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc88799",
   "metadata": {},
   "source": [
    "### 2. Cross validation and model training pipeline (includes splitting and feature scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_ml_pipe(X, y, groups, preprocessor, model, hyperparameters, score, \n",
    "                  randomized_iter, random_seed=1030):\n",
    "    \n",
    "    \"\"\"A function to collate performance of multiple model runs and optimize\n",
    "    hyperparameters through GridSearchCV.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : Unprocessed feature matrix\n",
    "    y : Target variable\n",
    "    preprocessor : A column transformer object that defines preprocessing on \n",
    "                    each feature; pass None if not required\n",
    "    model : Initialized model\n",
    "    model_params : Dict object of hyperparameters/regularization params\n",
    "                    to pass to GridSearchCV\n",
    "    score : Sklearn's scorer object (or metric string) that specifies\n",
    "            GridSearchCV scoring strategy\n",
    "    randomized_iter : Number of random iterations to run through to \n",
    "                        pick optimized params.\n",
    "      \n",
    "    Returns\n",
    "    -------\n",
    "    trial_results : list of dictionaries with salient information of each GSCV run\"\"\"\n",
    "    \n",
    "    trial_results = []\n",
    "    \n",
    "    for i in range(1,randomized_iter+1):\n",
    "        print('Running trial {}'.format(i))\n",
    "        random_state = random_seed*i\n",
    "        \n",
    "        iter_info = {'trail_iter':i,\n",
    "                     'random_state':random_state}\n",
    "        \n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=6, random_state=random_state)\n",
    "        other_index, test_index = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "        X_other, y_other, groups_other = X.iloc[other_index], y.iloc[other_index], groups.iloc[other_index]\n",
    "        X_test, y_test, groups_test = X.iloc[test_index], y.iloc[test_index], groups.iloc[test_index]\n",
    "\n",
    "        gkf = GroupKFold(n_splits=7)\n",
    "\n",
    "        pipe = make_pipeline(std_scaler, model)\n",
    "        grid = GridSearchCV(pipe, param_grid=hyperparameters, scoring=score,\n",
    "                            cv=gkf, return_train_score=True, verbose=True, n_jobs=-1)\n",
    "        grid.fit(X_other, y_other, groups=groups_other)\n",
    "        \n",
    "        iter_info['grid'] = grid\n",
    "        \n",
    "        if grid.scorer_.__dict__['_sign']<0:\n",
    "            best_score = abs(grid.score(X_test,y_test))\n",
    "            maximized = False\n",
    "        else:\n",
    "            best_score = grid.score(X_test,y_test)\n",
    "            maximized = True\n",
    "        \n",
    "        iter_info['best_test_score'] = {'score':best_score, 'maximized':maximized}\n",
    "        iter_info['best_params'] = grid.best_params_\n",
    "        iter_info['y_test_pred'] = grid.predict(X_test)\n",
    "        iter_info['cv_results'] = grid.cv_results_\n",
    "        \n",
    "        trial_results.append(iter_info)\n",
    "        print('Completed trial {}'.format(i))\n",
    "        \n",
    "    return trial_results\n",
    "\n",
    "\n",
    "def gather_trial_results(df, exclftrs, target, groupftr, preprocessor, model, \n",
    "                         hyperparameters, score, trials, trial_type):\n",
    "    X = df.drop(columns=exclftrs)\n",
    "    y = df[target]\n",
    "    groups = df[groupftr]\n",
    "    trial_results = group_ml_pipe(X, y, groups, preprocessor, model, hyperparameters, score, \n",
    "                                  randomized_iter=trials)\n",
    "    \n",
    "    for result in trial_results:\n",
    "        result['trial_type']=trial_type\n",
    "    return trial_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9289ee",
   "metadata": {},
   "source": [
    "### 3. Tune hyperparameters and collate best models for each random state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6afee5",
   "metadata": {},
   "source": [
    "#### Logistic Regression with time-freq features and DCT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd97654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_arr = np.logspace(-5,5,11,base=10)\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "model = LogisticRegression()\n",
    "hyperparameters = {\n",
    "    'logisticregression__C': 1/alpha_arr,\n",
    "    'logisticregression__penalty':['l2'],\n",
    "    'logisticregression__max_iter':[10000],\n",
    "    'logisticregression__multi_class':['ovr'],\n",
    "    'logisticregression__solver':['liblinear']\n",
    "}\n",
    "\n",
    "score = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# collate Logistic Regression results with time-freq feature set\n",
    "lr_timefreq_results = gather_trial_results(df=time_freq_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                            target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                            hyperparameters=hyperparameters, score=score,\n",
    "                                            trials=5, trial_type='time-freq')\n",
    "\n",
    "# save best estimator results for each random state with time-freq feature set\n",
    "joblib.dump(lr_timefreq_results, '../results/lr_timefreq_results.pkl')\n",
    "\n",
    "# collate Logistic Regression results with DCT features\n",
    "lr_dct_results = gather_trial_results(df=dct_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                       target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                       hyperparameters=hyperparameters, score=score,\n",
    "                                       trials=5, trial_type='dct')\n",
    "\n",
    "# save best estimator results for each random state with DCT feature set\n",
    "joblib.dump(lr_dct_results, '../results/lr_dct_results.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b62ef3e",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier with time-freq features and DCT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce41b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "model = SVC()\n",
    "hyperparameters = {'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "                  'svc__gamma': [0.01, 0.05, 0.1, 0.5, 1]}\n",
    "score = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# collate SVC results with time-freq feature set\n",
    "svc_timefreq_results = gather_trial_results(df=time_freq_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                            target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                            hyperparameters=hyperparameters, score=score, \n",
    "                                            trials=5, trial_type='time-freq')\n",
    "\n",
    "# save best estimator results for each random state with time-freq feature set\n",
    "joblib.dump(svc_timefreq_results, '../results/svc_timefreq_results.pkl')\n",
    "\n",
    "\n",
    "# collate SVC results with DCT features\n",
    "svc_dct_results = gather_trial_results(df=dct_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                       target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                       hyperparameters=hyperparameters, score=score, \n",
    "                                       trials=5, trial_type='dct')\n",
    "\n",
    "# save best estimator results for each random state with DCT feature set\n",
    "joblib.dump(svc_dct_results, '../results/svc_dct_results.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2111b983",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier with time-freq features and DCT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a56cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "model = RandomForestClassifier()\n",
    "hyperparameters = {\n",
    "    'randomforestclassifier__max_features': [0.25, 0.5, 0.75, 1.0],\n",
    "    'randomforestclassifier__max_depth': [2, 4, 6, 8, 10, 12, 14]\n",
    "}\n",
    "\n",
    "score = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# collate Random Forest Classifier results with time-freq feature set\n",
    "rfc_timefreq_results = gather_trial_results(df=time_freq_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                            target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                            hyperparameters=hyperparameters, score=score,\n",
    "                                            trials=5, trial_type='time-freq')\n",
    "\n",
    "# save best estimator results for each random state with time-freq feature set\n",
    "joblib.dump(rfc_timefreq_results, '../results/rfc_timefreq_results.pkl')\n",
    "\n",
    "\n",
    "# collate Random Forest Classifier results with DCT features\n",
    "rfc_dct_results = gather_trial_results(df=dct_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                       target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                       hyperparameters=hyperparameters, score=score,\n",
    "                                       trials=5, trial_type='dct')\n",
    "\n",
    "# save best estimator results for each random state with DCT feature set\n",
    "joblib.dump(rfc_dct_results, '../results/rfc_dct_results.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403f4879",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier with time-freq features and DCT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59411ef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "model = xgboost.XGBClassifier(use_label_encoder=True, objective='multi:softprob', verbosity = 0, silent = True)\n",
    "\n",
    "hyperparameters = {\n",
    "    'xgbclassifier__learning_rate': [0.01,0.025,0.05,0.1,0.25,0.5,1],\n",
    "    'xgbclassifier__max_depth': [2, 4, 6, 8, 10, 12, 14]\n",
    "}\n",
    "\n",
    "score = make_scorer(f1_score, average='macro')\n",
    "\n",
    "# collate XGBoost Classifier results with time-freq feature set\n",
    "xgb_timefreq_results = gather_trial_results(df=time_freq_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                            target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                            hyperparameters=hyperparameters, score=score,\n",
    "                                            trials=5, trial_type='time-freq')\n",
    "\n",
    "# save best estimator results for each random state with time-freq feature set\n",
    "joblib.dump(xgb_timefreq_results, '../results/xgb_timefreq_results.pkl')\n",
    "\n",
    "\n",
    "# collate XGBoost Classifier results with DCT feature set\n",
    "xgb_dct_results = gather_trial_results(df=dct_domain_df, exclftrs=['epoch_start','epoch_end','class','user'],\n",
    "                                            target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                            hyperparameters=hyperparameters, score=score,\n",
    "                                            trials=5, trial_type='time-freq')\n",
    "\n",
    "# save best estimator results for each random state with DCT feature set\n",
    "joblib.dump(xgb_dct_results, '../results/xgb_dct_results.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af98cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsemproj",
   "language": "python",
   "name": "mlsemproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
