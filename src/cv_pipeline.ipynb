{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca12e366",
   "metadata": {},
   "source": [
    "#### Import necessary libraries and set display options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d5550e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from detecta import detect_peaks\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_rows',200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fe64799",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_domain_df = pd.read_csv('../data/time_domain_windows.csv')\n",
    "freq_domain_df = pd.read_csv('../data/freq_domain_windows.csv')\n",
    "time_freq_domain_df = pd.read_csv('../data/time_freq_domain_windows.csv')\n",
    "dct_domain_df = pd.read_csv('../data/dct_domain_windows.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc88799",
   "metadata": {},
   "source": [
    "### 5. Splitting and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49061772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, GroupShuffleSplit, GroupKFold, ParameterGrid, train_test_split, ShuffleSplit, BaseShuffleSplit, PredefinedSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e585b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_ml_pipe(X, y, groups, preprocessor, model, hyperparameters, score, \n",
    "                  randomized_iter, random_seed=1030):\n",
    "    \n",
    "    \"\"\"A function to collate performance of multiple model runs and optimize\n",
    "    hyperparameters through GridSearchCV.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : Unprocessed feature matrix\n",
    "    y : Target variable\n",
    "    preprocessor : A column transformer object that defines preprocessing on \n",
    "                    each feature; pass None if not required\n",
    "    model : Initialized model\n",
    "    model_params : Dict object of hyperparameters/regularization params\n",
    "                    to pass to GridSearchCV\n",
    "    score : Sklearn's scorer object (or metric string) that specifies\n",
    "            GridSearchCV scoring strategy\n",
    "    randomized_iter : Number of random iterations to run through to \n",
    "                        pick optimized params.\n",
    "      \n",
    "    Returns\n",
    "    -------\n",
    "    trial_results : list of dictionaries with salient information of each GSCV run\"\"\"\n",
    "    \n",
    "    trial_results = []\n",
    "    \n",
    "    for i in range(1,randomized_iter+1):\n",
    "        print('Running trial {}'.format(i))\n",
    "        random_state = random_seed*i\n",
    "        \n",
    "        iter_info = {'trail_iter':i,\n",
    "                     'random_state':random_state}\n",
    "        \n",
    "        gss = GroupShuffleSplit(n_splits=1, test_size=6, random_state=random_state)\n",
    "        other_index, test_index = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "        X_other, y_other, groups_other = X.iloc[other_index], y.iloc[other_index], groups.iloc[other_index]\n",
    "        X_test, y_test, groups_test = X.iloc[test_index], y.iloc[test_index], groups.iloc[test_index]\n",
    "\n",
    "        gkf = GroupKFold(n_splits=7)\n",
    "\n",
    "        pipe = make_pipeline(std_scaler, model)\n",
    "        grid = GridSearchCV(pipe, param_grid=hyperparameters, scoring=score,\n",
    "                            cv=gkf, return_train_score=True, verbose=True, n_jobs=-1)\n",
    "        grid.fit(X_other, y_other, groups=groups_other)\n",
    "        \n",
    "        iter_info['grid'] = grid\n",
    "        \n",
    "        if grid.scorer_.__dict__['_sign']<0:\n",
    "            best_score = abs(grid.score(X_test,y_test))\n",
    "            maximized = False\n",
    "        else:\n",
    "            best_score = grid.score(X_test,y_test)\n",
    "            maximized = True\n",
    "        \n",
    "        iter_info['best_test_score'] = {'score':best_score, 'maximized':maximized}\n",
    "        iter_info['best_params'] = grid.best_params_\n",
    "        iter_info['y_test_pred'] = grid.predict(X_test)\n",
    "        iter_info['cv_results'] = grid.cv_results_\n",
    "        \n",
    "        trial_results.append(iter_info)\n",
    "        print('Completed trial {}'.format(i))\n",
    "        \n",
    "    return trial_results\n",
    "\n",
    "\n",
    "def gather_trial_results(df, exclftrs, target, groupftr, preprocessor, model, \n",
    "                         hyperparameters, score, trials=5, trial_type='time-freq'):\n",
    "    X = df.drop(columns=exclftrs)\n",
    "    y = df[target]\n",
    "    groups = df[groupftr]\n",
    "    trial_results = group_ml_pipe(X, y, groups, preprocessor, model, hyperparameters, score, \n",
    "                                  randomized_iter=trials)\n",
    "    \n",
    "    for result in trial_results:\n",
    "        result['trial_type']=trial_type\n",
    "    return trial_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c63db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 1\n",
      "Fitting 7 folds for each of 25 candidates, totalling 175 fits\n",
      "Completed trial 1\n",
      "Running trial 2\n",
      "Fitting 7 folds for each of 25 candidates, totalling 175 fits\n",
      "Completed trial 2\n",
      "Running trial 3\n",
      "Fitting 7 folds for each of 25 candidates, totalling 175 fits\n",
      "Completed trial 3\n",
      "Running trial 4\n",
      "Fitting 7 folds for each of 25 candidates, totalling 175 fits\n"
     ]
    }
   ],
   "source": [
    "std_scaler = StandardScaler()\n",
    "model = SVC()\n",
    "hyperparameters = {'svc__C': [0.01, 0.1, 1, 10, 100],\n",
    "                  'svc__gamma': [0.01, 0.05, 0.1, 0.5, 1]}\n",
    "score = make_scorer(f1_score, average='macro')\n",
    "\n",
    "svc_timefreq_results = gather_trial_results(df=time_freq_domain_df, exclftrs=['epoch_start','epoch_end','class'],\n",
    "                                            target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                            hyperparameters=hyperparameters, score=score)\n",
    "\n",
    "svc_dct_results = gather_trial_results(df=dct_domain_df, exclftrs=['epoch_start','epoch_end','class'],\n",
    "                                            target='class', groupftr='user', preprocessor=std_scaler, model=model,\n",
    "                                            hyperparameters=hyperparameters, score=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a56cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running trial 1\n",
      "Fitting 7 folds for each of 42 candidates, totalling 294 fits\n",
      "Completed trial 1\n",
      "Running trial 2\n",
      "Fitting 7 folds for each of 42 candidates, totalling 294 fits\n",
      "Completed trial 2\n",
      "Running trial 3\n",
      "Fitting 7 folds for each of 42 candidates, totalling 294 fits\n",
      "Completed trial 3\n",
      "Running trial 4\n",
      "Fitting 7 folds for each of 42 candidates, totalling 294 fits\n",
      "Completed trial 4\n",
      "Running trial 5\n",
      "Fitting 7 folds for each of 42 candidates, totalling 294 fits\n",
      "Completed trial 5\n",
      "Running trial 6\n",
      "Fitting 7 folds for each of 42 candidates, totalling 294 fits\n",
      "Completed trial 6\n",
      "Running trial 7\n",
      "Fitting 7 folds for each of 42 candidates, totalling 294 fits\n",
      "Completed trial 7\n",
      "Running trial 8\n",
      "Fitting 7 folds for each of 42 candidates, totalling 294 fits\n",
      "Completed trial 8\n",
      "Running trial 9\n",
      "Fitting 7 folds for each of 42 candidates, totalling 294 fits\n",
      "Completed trial 9\n",
      "Running trial 10\n",
      "Fitting 7 folds for each of 42 candidates, totalling 294 fits\n",
      "Completed trial 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = time_freq_domain_df.drop(columns=['epoch_start','epoch_end','class']) # exclude time, target variable and class from features\n",
    "y = time_freq_domain_df['class']\n",
    "groups = time_freq_domain_df['user']\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "hyperparameters = {\n",
    "    'randomforestclassifier__n_estimators': [1, 3, 10, 30, 50, 100],\n",
    "    'randomforestclassifier__max_depth': [2, 4, 6, 8, 10, 12, 14]\n",
    "}\n",
    "\n",
    "score = make_scorer(f1_score, average='macro')\n",
    "\n",
    "rfc_trial_results = group_ml_pipe(X, y, groups, std_scaler, model, hyperparameters, score,\n",
    "                                  randomized_iter=10, random_seed=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c1688ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8817747517272426, 0.019850264614544075)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_trial_best_scores = np.zeros(len(rfc_trial_results))\n",
    "for i,result in enumerate(rfc_trial_results):\n",
    "    rfc_trial_best_scores[i] = result['best_test_score']['score']\n",
    "\n",
    "np.mean(rfc_trial_best_scores),np.std(rfc_trial_best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77e8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsemproj",
   "language": "python",
   "name": "mlsemproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
